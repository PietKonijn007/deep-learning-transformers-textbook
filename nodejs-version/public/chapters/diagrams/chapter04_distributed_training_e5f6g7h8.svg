<?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1200 900">
  <defs>
    <style>
      .title { font: bold 20px sans-serif; fill: #2d3748; }
      .subtitle { font: bold 16px sans-serif; fill: #2d3748; }
      .label { font: 14px sans-serif; fill: #2d3748; }
      .small-label { font: 12px sans-serif; fill: #4a5568; }
      .annotation { font: 13px sans-serif; fill: #718096; }
      .metric { font: bold 14px sans-serif; fill: #38a169; }
      .gpu { fill: #667eea; stroke: #4c51bf; stroke-width: 2; }
      .model { fill: #764ba2; stroke: #553c9a; stroke-width: 1.5; }
      .data { fill: #48bb78; stroke: #38a169; stroke-width: 1.5; }
      .arrow { stroke: #4a5568; stroke-width: 2; fill: none; marker-end: url(#arrowhead); }
      .comm-line { stroke: #f093fb; stroke-width: 2; stroke-dasharray: 3,3; }
    </style>
    <marker id="arrowhead" markerWidth="8" markerHeight="8" refX="7" refY="2.5" orient="auto">
      <polygon points="0 0, 8 2.5, 0 5" fill="#4a5568" />
    </marker>
  </defs>
  
  <!-- Title -->
  <text x="600" y="30" class="title" text-anchor="middle">Distributed Training Paradigms</text>
  
  <!-- Data Parallelism Column -->
  <g transform="translate(50, 80)">
    <text x="150" y="0" class="subtitle" text-anchor="middle">Data Parallelism</text>
    
    <!-- GPU 1 -->
    <rect x="20" y="40" width="120" height="140" class="gpu" rx="5"/>
    <text x="80" y="60" class="label" text-anchor="middle">GPU 1</text>
    <rect x="30" y="70" width="100" height="30" class="model" rx="3"/>
    <text x="80" y="90" class="small-label" text-anchor="middle">Full Model</text>
    <rect x="30" y="110" width="100" height="30" class="data" rx="3"/>
    <text x="80" y="130" class="small-label" text-anchor="middle">Batch 1</text>
    
    <!-- GPU 2 -->
    <rect x="160" y="40" width="120" height="140" class="gpu" rx="5"/>
    <text x="220" y="60" class="label" text-anchor="middle">GPU 2</text>
    <rect x="170" y="70" width="100" height="30" class="model" rx="3"/>
    <text x="220" y="90" class="small-label" text-anchor="middle">Full Model</text>
    <rect x="170" y="110" width="100" height="30" class="data" rx="3"/>
    <text x="220" y="130" class="small-label" text-anchor="middle">Batch 2</text>
    
    <!-- Communication -->
    <line x1="80" y1="190" x2="220" y2="190" class="comm-line"/>
    <text x="150" y="210" class="annotation" text-anchor="middle">Gradient Sync</text>
    
    <!-- Characteristics -->
    <rect x="10" y="240" width="280" height="180" fill="#f7fafc" stroke="#cbd5e0" stroke-width="1" rx="5"/>
    <text x="150" y="265" class="label" text-anchor="middle">Characteristics</text>
    <text x="20" y="290" class="annotation">• Model replicated</text>
    <text x="20" y="310" class="annotation">• Different data per GPU</text>
    <text x="20" y="330" class="annotation">• Gradients synchronized</text>
    <text x="20" y="350" class="annotation">• Scales to 64-128 GPUs</text>
    <text x="150" y="380" class="metric" text-anchor="middle">Efficiency: 75-90%</text>
    <text x="150" y="405" class="annotation" text-anchor="middle">Best for: Models fitting in GPU</text>
  </g>
  
  <!-- Pipeline Parallelism Column -->
  <g transform="translate(425, 80)">
    <text x="150" y="0" class="subtitle" text-anchor="middle">Pipeline Parallelism</text>
    
    <!-- GPU 1 - Layers 1-4 -->
    <rect x="20" y="40" width="120" height="140" class="gpu" rx="5"/>
    <text x="80" y="60" class="label" text-anchor="middle">GPU 1</text>
    <rect x="30" y="70" width="100" height="30" class="model" rx="3"/>
    <text x="80" y="90" class="small-label" text-anchor="middle">Layers 1-4</text>
    <rect x="30" y="110" width="100" height="30" class="data" rx="3"/>
    <text x="80" y="130" class="small-label" text-anchor="middle">Batch 1</text>
    
    <!-- GPU 2 - Layers 5-8 -->
    <rect x="160" y="40" width="120" height="140" class="gpu" rx="5"/>
    <text x="220" y="60" class="label" text-anchor="middle">GPU 2</text>
    <rect x="170" y="70" width="100" height="30" class="model" rx="3"/>
    <text x="220" y="90" class="small-label" text-anchor="middle">Layers 5-8</text>
    <rect x="170" y="110" width="100" height="30" class="data" rx="3"/>
    <text x="220" y="130" class="small-label" text-anchor="middle">Batch 1</text>
    
    <!-- Pipeline flow -->
    <path d="M 140 110 L 160 110" class="arrow"/>
    <text x="150" y="105" class="annotation" text-anchor="middle">→</text>
    
    <!-- Characteristics -->
    <rect x="10" y="240" width="280" height="180" fill="#f7fafc" stroke="#cbd5e0" stroke-width="1" rx="5"/>
    <text x="150" y="265" class="label" text-anchor="middle">Characteristics</text>
    <text x="20" y="290" class="annotation">• Model partitioned by layers</text>
    <text x="20" y="310" class="annotation">• Sequential data flow</text>
    <text x="20" y="330" class="annotation">• Pipeline bubbles reduce efficiency</text>
    <text x="20" y="350" class="annotation">• Scales to 16-32 stages</text>
    <text x="150" y="380" class="metric" text-anchor="middle">Efficiency: 60-80%</text>
    <text x="150" y="405" class="annotation" text-anchor="middle">Best for: Very large models</text>
  </g>
  
  <!-- Tensor Parallelism Column -->
  <g transform="translate(800, 80)">
    <text x="150" y="0" class="subtitle" text-anchor="middle">Tensor Parallelism</text>
    
    <!-- GPU 1 - Left half -->
    <rect x="20" y="40" width="120" height="140" class="gpu" rx="5"/>
    <text x="80" y="60" class="label" text-anchor="middle">GPU 1</text>
    <rect x="30" y="70" width="100" height="30" class="model" rx="3"/>
    <text x="80" y="90" class="small-label" text-anchor="middle">Left Half</text>
    <text x="80" y="105" class="small-label" text-anchor="middle">of Layers</text>
    <rect x="30" y="120" width="100" height="30" class="data" rx="3"/>
    <text x="80" y="140" class="small-label" text-anchor="middle">Same Batch</text>
    
    <!-- GPU 2 - Right half -->
    <rect x="160" y="40" width="120" height="140" class="gpu" rx="5"/>
    <text x="220" y="60" class="label" text-anchor="middle">GPU 2</text>
    <rect x="170" y="70" width="100" height="30" class="model" rx="3"/>
    <text x="220" y="90" class="small-label" text-anchor="middle">Right Half</text>
    <text x="220" y="105" class="small-label" text-anchor="middle">of Layers</text>
    <rect x="170" y="120" width="100" height="30" class="data" rx="3"/>
    <text x="220" y="140" class="small-label" text-anchor="middle">Same Batch</text>
    
    <!-- Communication -->
    <line x1="80" y1="190" x2="220" y2="190" class="comm-line"/>
    <line x1="220" y1="195" x2="80" y2="195" class="comm-line"/>
    <text x="150" y="210" class="annotation" text-anchor="middle">All-Reduce</text>
    
    <!-- Characteristics -->
    <rect x="10" y="240" width="280" height="180" fill="#f7fafc" stroke="#cbd5e0" stroke-width="1" rx="5"/>
    <text x="150" y="265" class="label" text-anchor="middle">Characteristics</text>
    <text x="20" y="290" class="annotation">• Operations partitioned</text>
    <text x="20" y="310" class="annotation">• Same data per GPU</text>
    <text x="20" y="330" class="annotation">• Frequent communication</text>
    <text x="20" y="350" class="annotation">• Requires fast interconnect</text>
    <text x="150" y="380" class="metric" text-anchor="middle">Efficiency: 80-90%</text>
    <text x="150" y="405" class="annotation" text-anchor="middle">Best for: Huge single layers</text>
  </g>
  
  <!-- Hybrid Approach Example -->
  <rect x="50" y="550" width="1100" height="300" fill="#fef5e7" stroke="#f39c12" stroke-width="2" rx="5"/>
  <text x="600" y="585" class="subtitle" text-anchor="middle">Hybrid Approach: GPT-3 Training (1,024 GPUs)</text>
  
  <g transform="translate(100, 620)">
    <text x="0" y="0" class="label">8-way Tensor Parallelism</text>
    <rect x="0" y="10" width="40" height="30" class="gpu" rx="2"/>
    <rect x="45" y="10" width="40" height="30" class="gpu" rx="2"/>
    <rect x="90" y="10" width="40" height="30" class="gpu" rx="2"/>
    <text x="140" y="30" class="annotation">... (8 GPUs per layer)</text>
    <text x="0" y="60" class="annotation">↓ Each layer split across 8 GPUs</text>
  </g>
  
  <g transform="translate(450, 620)">
    <text x="0" y="0" class="label">16-way Pipeline Parallelism</text>
    <rect x="0" y="10" width="40" height="30" class="gpu" rx="2"/>
    <text x="45" y="30" class="annotation">→</text>
    <rect x="60" y="10" width="40" height="30" class="gpu" rx="2"/>
    <text x="105" y="30" class="annotation">→</text>
    <rect x="120" y="10" width="40" height="30" class="gpu" rx="2"/>
    <text x="165" y="30" class="annotation">... (16 stages)</text>
    <text x="0" y="60" class="annotation">↓ 16 layer groups in pipeline</text>
  </g>
  
  <g transform="translate(850, 620)">
    <text x="0" y="0" class="label">8-way Data Parallelism</text>
    <rect x="0" y="10" width="40" height="30" class="gpu" rx="2"/>
    <rect x="0" y="45" width="40" height="30" class="gpu" rx="2"/>
    <rect x="0" y="80" width="40" height="30" class="gpu" rx="2"/>
    <text x="50" y="60" class="annotation">8 replicas</text>
    <text x="50" y="80" class="annotation">of entire</text>
    <text x="50" y="100" class="annotation">pipeline</text>
  </g>
  
  <text x="600" y="770" class="label" text-anchor="middle">Total: 8 × 16 × 8 = 1,024 GPUs</text>
  <text x="600" y="795" class="annotation" text-anchor="middle">Combines strengths of all three approaches for maximum scale</text>
  <text x="600" y="820" class="annotation" text-anchor="middle">Overall efficiency: ~50-60% (communication overhead at this scale)</text>
</svg>
